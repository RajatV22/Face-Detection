{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2213bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading PyPDF2-2.11.0-py3-none-any.whl (220 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from PyPDF2) (3.10.0.2)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46d4bc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2==1.26.0\n",
      "  Downloading PyPDF2-1.26.0.tar.gz (77 kB)\n",
      "Building wheels for collected packages: PyPDF2\n",
      "  Building wheel for PyPDF2 (setup.py): started\n",
      "  Building wheel for PyPDF2 (setup.py): finished with status 'done'\n",
      "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61101 sha256=915b90e29b627d3369703ff4f10a5a38fea92070c8cd8fec349ac0e83d2829d3\n",
      "  Stored in directory: c:\\users\\rvsha\\appdata\\local\\pip\\cache\\wheels\\d9\\dc\\ec\\72da68331f30074b9950c1737c23cb8a67484e61498bc9713d\n",
      "Successfully built PyPDF2\n",
      "Installing collected packages: PyPDF2\n",
      "  Attempting uninstall: PyPDF2\n",
      "    Found existing installation: PyPDF2 2.11.0\n",
      "    Uninstalling PyPDF2-2.11.0:\n",
      "      Successfully uninstalled PyPDF2-2.11.0\n",
      "Successfully installed PyPDF2-1.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088788bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8c68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "219623 \n",
      "TTEfa farer as, feret \n",
      "Central Board of Secondary Educafion, Delhi \n",
      "HTEZTeR taete qTeT (: 2011-13) \n",
      "SECONDARY SCHOOL EXAMINATION (SESSION: 2011-2013) \n",
      "33 tre HE faroT HT 7 Grade Sheet cum Certificate of Perfornmanceolare . \n",
      "0892414 Registration No. M113/06883/0042S.No.SSE/20132\n",
      "TE HrO faRTGTta Thisis to certify thatrgaur RollNo. 4245239 ROHITKUMAR VERMA \n",
      "Mother's/Father's/Guardian's Name NEELAM \n",
      "TGR Date of Birth PRADEEPKUMAR VERMA \n",
      "faerer School 04/11/1998 4TH NOVEMBER NINETEEN HUNDRED NINETY EIGHT \n",
      "T gR KEI has performed as follows: 06883-CENTRAL RAILWAY SEC E M SCH & JR.COLLKALYAN MR \n",
      "1 81&TTUT5 TRT Academic Performance apT Partl 2fêrn a Scholastic Areas \n",
      "oET Class IX &T Cas5 X \n",
      "al (FAGA) Subject Code and Name \n",
      "A Gradie Grade Poip \n",
      "31 B1 08 B1 A2 09 101 ENGLISH COMM. B1 \n",
      "A2 09 B1 B1 002 HINDI COURSE-A A2 B2 8 BT \n",
      "041 MATHEMATICS A1 2 A2 09 AZ B1 AZ 09 \n",
      "A2** As per Scheme of Studies CGPAs hi arer of Grade Painta oigaiyed in all the \n",
      "sunjecta exclucing An indicative equivalence of Grade Point and Percentage of Magke cambe caleulated as 086 SCIENCE B1 B1 B1 08 AT C1 09 \n",
      "087 SOCIAL SCIENCE B2 08 d Pe \n",
      "A2 B1 A2 09 A2 31 \n",
      "165 FOUNDATHONE'cumulative Grade At Averafe (CGP) Subject wise indicarive percentpeof marks9.3xGP ol the sufect \n",
      "Overall indicative percentags of nmariks 9.5xaPA. 08 B1 B1 ST 08 \n",
      "T Part- 2: HE-ITra anra cCo-Schola@R Areas \n",
      "7T ClasS X 2(3)(A) itm a187 \n",
      "Life Skills RT Class DX \n",
      "Grade uRico EE Descriptive Indicators quicHc Descriptive Indicators arade \n",
      "Makes decisions, has ideas but needs to express them better. Rarely exhibits \n",
      "decision making skills. Is aware of personal strengths & weaknesses. Always analyses problems \n",
      "with relevant information & chooses the best a lternative. Always shows \n",
      "originality & innovation. Is alwaysable to find creative & constructiveA frem a1TC \n",
      "Thinking Skills \n",
      "solutions to problems.\n",
      "Is always empathetic, accepts criticism openly, exhibits interpersonal skill. \n",
      "Is an effective communicator & always follows norms & social conducts. Can offer help to classmates and differently abled students when needed and is \n",
      "A receptive to feed back. Needs to develop better listening skills. Social Skilts often demonstrates leadership skills. Always listens actively& get along \n",
      "well with others Shares feelings with peer group, teachers and parents appropriately at times. Can \n",
      "identify negative emotions and stress, but needsguidance to deal with it. Is able to identify the causes of stress and can handle them effectively. If \n",
      "unsuccessful, gracefully takesthe task again.Always remains calm in A \n",
      "Emotional Skills adverse conditions. can express emotions with an awareness of \n",
      "Consequences\n",
      "2 ()(B)Td RTeITWork Education \n",
      "Has a satisfactory grasp of work activities, shows involvement, is helpful and \n",
      "usually adheres to timelines. Is innovative and gets involved in work activities. Is readyto assist and \n",
      "guide others. Displays understanding of real life situations. \n",
      "Work Education C \n",
      "2 ((C) TK EFT cT Visual and Performing Arts: \n",
      "ge7 att wreefaverc Attempts to learn and participate in art related activities, needs motivation to \n",
      "Visual & Performingdemonstrate originality. Rarely exhibíts creative expression. \n",
      "Arts Participates actively in art related activities at different levels. Is aesthetic, \n",
      "innovative, creative, and interpretive and has good observation skills, Is \n",
      "able to enjoy art forms and pertormances. D A \n",
      "2 (D) 3rfrgfRri gei Attitudes and Values \n",
      "(a sft) towards a S Descriptive Tndicators rui 8 Descriptive Indicators \n",
      "Generally shows respect and courtesy towards teachers but may at times \n",
      "need to be rebuked. Is always respectful and courteous towards teachers and elders. Exhibits a \n",
      "3121d D A positive attitude towards learning and adheres to school and class norms. \n",
      "Communicates effectively with teachers and takes criticism positively. Teachers\n",
      "Has good relations with most of the peer group. Is generally sensitive \n",
      "towards classmates and treats them equally. Expresses ideas and interacts effectively with classmates. Is sensitive \n",
      "towards peers and differently abled schoolmates. Respects opposite gender, \n",
      "Is receptive to ideas and opinions. School Mates \n",
      "A regular participant in most of the school programmes and events. Is quite \n",
      "responsible and usually takes care of the school property. Attaches a lot of importance to the schoolprogrammes and events and \n",
      "regularly participates in the various activities. Displays leadership skills and faerey rg \n",
      "Is regular and punctual. mes & \n",
      "e \n",
      "Abides by rules and regulations, adheres to value systems. Is honest, \n",
      "courteous and possesses leadership qualities. Respects national flag and \n",
      "symbols. Is sensitive to diversity, cares for the underprivileged and respects Attempts to follow value systems and rules. Is honest and respects \n",
      "A UTtoT diversity. Sometimes displays responsible behaviour. \n",
      "Value Systerns \n",
      "Opposite gender. \n",
      "3 ()(A) E-7749 61 Co-Curricular Activities: TRT Part-3 H-TRH 2TrtTa Co-Cureicular Activities \n",
      "3PTecC ActiviEy \n",
      "Actively participates in literary and creative events at school and \n",
      "inter-school level. Is an avid reader and appreciates written and spoken \n",
      "texts, expresses ideas and opinions clearly. Literary and Creative Skills ls able to understand literary texts and keen to develop creative skills. \n",
      "Literary.and Creative Skills \n",
      "Displays scientific temperament in everyday life. Is a keen observer. Plans \n",
      "and participates in scientific activities at different levels. Verifies existing \n",
      "sclentific knowledge before accepting it. Is efficient in conducting \n",
      "experiments. Works hard to deliver assigned jobs effectively, is a motivated member of \n",
      "the clubs and tries to work in teams.Organizational and D A eadership Skills \n",
      "Scientific Skills \n",
      "3 (0) T2 eRHRT 191eTT Health and Plhysical Education \n",
      "T6 Activily \n",
      "Is good in a particular sport,but needsmore training. Exhibits discipline, \n",
      "punctuality and team spirit. Displays talent in an identified sport, has represented school. Possesses \n",
      "c endurance, strength, agility and flexibility. Demonstrates a healthy team \n",
      "spirit, sportsmanship and discipline. Sportsndugeo\n",
      "poTsthro-Ano Ee.) \n",
      "Sportslndigenous \n",
      "Sports(Kho-Kho Etc.)\n",
      "Scouting and Guiding Shows an inclination to serve people less fortunate. Discharges tasks \n",
      "assigned effectively. Displays leadership skills and a high sense of \n",
      "responsiblity and discipline. Has an independent thought process. \n",
      "Regularly attends camps. Shows interest in taking up community service, participates in camps.\n",
      "Complete the assigned tasks efectively. A \n",
      "Scouting and Guiding \n",
      "sE Upgradied Grade TROTH Result : QUALIFIED FOR ADMISsION TO HIGHER CLASSES \n",
      "(Mckaxma Phincipal \n",
      "C. RLY. SECONDARY SCHOOL (EM) & \n",
      "Jr. CollegeofAtS, Selehce &Commerce ( alyan (w) 421 301hooi ft Dehi \n",
      "Controller of Examinations fie Datad 26-05-2013 \n"
     ]
    }
   ],
   "source": [
    "#Creating a pdf file object\n",
    "pdf = open(\"downloads/10th.pdf\",\"rb\")\n",
    "\n",
    "#creating pdf reader object\n",
    "pdf_reader = PyPDF2.PdfFileReader(pdf)\n",
    "\n",
    "#checking number of pages in a pdf file\n",
    "print(pdf_reader.numPages)\n",
    "\n",
    "#creating a page object\n",
    "page = pdf_reader.getPage(0)\n",
    "\n",
    "#finally extracting text from the page\n",
    "print(page.extractText())\n",
    "\n",
    "#closing the pdf file\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9302d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textract"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n",
      "Collecting argcomplete~=1.10.0\n",
      "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting six~=1.12.0\n",
      "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting xlrd~=1.2.0\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "Requirement already satisfied: SpeechRecognition~=3.8.1 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from textract) (3.8.1)\n",
      "Collecting extract-msg<=0.29.*\n",
      "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
      "Collecting python-pptx~=0.6.18\n",
      "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
      "Collecting chardet==3.*\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Collecting pdfminer.six==20191110\n",
      "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
      "Collecting docx2txt~=0.8\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "Collecting beautifulsoup4~=4.8.0\n",
      "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.15.0-cp35-abi3-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from beautifulsoup4~=4.8.0->textract) (2.2.1)\n",
      "Collecting imapclient==2.1.0\n",
      "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
      "Collecting ebcdic>=1.1.1\n",
      "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
      "Collecting tzlocal>=2.1\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Collecting compressed-rtf>=1.0.6\n",
      "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
      "Requirement already satisfied: olefile>=0.46 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from python-pptx~=0.6.18->textract) (4.6.3)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from python-pptx~=0.6.18->textract) (8.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from python-pptx~=0.6.18->textract) (3.0.1)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.4-py2.py3-none-any.whl (336 kB)\n",
      "Building wheels for collected packages: docx2txt, compressed-rtf, python-pptx\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=e4d4f0d0d333db42561e875322b11f8a99d75c89aabcd782934959d0dd0c537b\n",
      "  Stored in directory: c:\\users\\rvsha\\appdata\\local\\pip\\cache\\wheels\\40\\75\\01\\e6c444034338bde9c7947d3467807f889123465c2371e77418\n",
      "  Building wheel for compressed-rtf (setup.py): started\n",
      "  Building wheel for compressed-rtf (setup.py): finished with status 'done'\n",
      "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6200 sha256=c55ab711286dfbf38ec33355815d3dfe01756bdbaf3df5d6070c517ff62b4b3f\n",
      "  Stored in directory: c:\\users\\rvsha\\appdata\\local\\pip\\cache\\wheels\\e4\\67\\e4\\ba2159853bdd0fe99330aa1e384915108143a5370686ea446f\n",
      "  Building wheel for python-pptx (setup.py): started\n",
      "  Building wheel for python-pptx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470950 sha256=21d57bdc32596d25e9228bc2eb0100ff30b20210fb494d3e82edcb970cebbafe\n",
      "  Stored in directory: c:\\users\\rvsha\\appdata\\local\\pip\\cache\\wheels\\0e\\4a\\ed\\9653bc799915f52dce3f04d14946fbd85cce9c3cdedc9cfa71\n",
      "Successfully built docx2txt compressed-rtf python-pptx\n",
      "Installing collected packages: tzdata, six, pytz-deprecation-shim, tzlocal, pycryptodome, imapclient, ebcdic, compressed-rtf, chardet, xlrd, python-pptx, pdfminer.six, extract-msg, docx2txt, beautifulsoup4, argcomplete, textract\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 2.0.1\n",
      "    Uninstalling xlrd-2.0.1:\n",
      "      Successfully uninstalled xlrd-2.0.1\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.10.0\n",
      "    Uninstalling beautifulsoup4-4.10.0:\n",
      "      Successfully uninstalled beautifulsoup4-4.10.0\n",
      "Successfully installed argcomplete-1.10.3 beautifulsoup4-4.8.2 chardet-3.0.4 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 pdfminer.six-20191110 pycryptodome-3.15.0 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 textract-1.6.5 tzdata-2022.4 tzlocal-4.2 xlrd-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef954df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2, urllib.request , nltk\n",
    "from io import BytesIO\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ba046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the PDF\n",
    "wFile = urllib.request.urlopen('http://www.udri.org/pdf/02%20working%20paper%201.pdf')\n",
    "pdfreader = PyPDF2.PdfFileReader(BytesIO(wFile.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef0c3117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PyPDF2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d4a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting page 2 of the docuemnt\n",
    "pageObj = pdfreader.getPage(1)\n",
    "page2 = pageObj.extractText()\n",
    "#Cleaning the text\n",
    "punctuations = ['(',')',';',':','[',']',',','...','.']\n",
    "tokens = word_tokenize(page2)\n",
    "stop_words = stopwords.words('english')\n",
    "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03f6894f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '2014‐2034',\n",
       " 'Acknowledgements',\n",
       " 'The',\n",
       " 'Consultant',\n",
       " 'wishes',\n",
       " 'thank',\n",
       " 'following',\n",
       " 'individuals',\n",
       " 'Municipal',\n",
       " 'Corporation',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " 'invaluable',\n",
       " 'support',\n",
       " 'insights',\n",
       " 'contributions',\n",
       " 'towards',\n",
       " '‘',\n",
       " 'Working',\n",
       " 'Paper',\n",
       " '1',\n",
       " '–',\n",
       " 'Preparation',\n",
       " 'Base',\n",
       " 'Map',\n",
       " '’',\n",
       " 'preparation',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " 'Greater',\n",
       " 'Mumbai',\n",
       " '2014‐34',\n",
       " '\\uf0a7',\n",
       " 'Mr.',\n",
       " 'Subodh',\n",
       " 'Kumar',\n",
       " 'IAS',\n",
       " 'Municipal',\n",
       " 'Commissioner',\n",
       " '\\uf0a7',\n",
       " 'Mr.',\n",
       " 'Rajeev',\n",
       " 'Kuknoor',\n",
       " 'Chief',\n",
       " 'Engineer',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " '\\uf0a7',\n",
       " 'Mr.',\n",
       " 'Sudhir',\n",
       " 'Ghate',\n",
       " 'Deputy',\n",
       " 'Chief',\n",
       " 'Engineer',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " '\\uf0a7',\n",
       " 'Mr.',\n",
       " 'A.G.',\n",
       " 'Marathe',\n",
       " 'Deputy',\n",
       " 'Chief',\n",
       " 'Engineer',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " '\\uf0a7',\n",
       " 'Mr.',\n",
       " 'R.',\n",
       " 'Balachandran',\n",
       " 'Executive',\n",
       " 'Engineer',\n",
       " 'Town',\n",
       " 'Planning',\n",
       " 'Officer',\n",
       " 'Development',\n",
       " 'Plan',\n",
       " 'Our',\n",
       " 'gratitude',\n",
       " 'following',\n",
       " 'experts',\n",
       " 'invaluable',\n",
       " 'insights',\n",
       " 'support',\n",
       " '\\uf0a7',\n",
       " 'Mr.',\n",
       " 'V.K',\n",
       " 'Phatak',\n",
       " 'Former',\n",
       " 'Chief',\n",
       " 'Town',\n",
       " 'Planner',\n",
       " 'MMRDA',\n",
       " '\\uf0a7',\n",
       " 'Mr.',\n",
       " 'A.N',\n",
       " 'Kale',\n",
       " 'Former',\n",
       " 'Chief',\n",
       " 'Engineer',\n",
       " 'DP',\n",
       " '\\uf0a7',\n",
       " 'Mr.',\n",
       " 'A',\n",
       " 'S',\n",
       " 'Jain',\n",
       " 'Former',\n",
       " 'Dy',\n",
       " 'Chief',\n",
       " 'Engineer',\n",
       " 'DP',\n",
       " 'We',\n",
       " 'wish',\n",
       " 'especially',\n",
       " 'thank',\n",
       " 'MCGM',\n",
       " 'officers',\n",
       " 'Mr.',\n",
       " 'Jagdish',\n",
       " 'Talreja',\n",
       " 'Mr.',\n",
       " 'Dinesh',\n",
       " 'Naik',\n",
       " 'Mr.',\n",
       " 'Hiren',\n",
       " 'Daftardar',\n",
       " 'Ms.',\n",
       " 'Anita',\n",
       " 'Naik',\n",
       " 'continual',\n",
       " 'support',\n",
       " 'since',\n",
       " 'beginning',\n",
       " 'project',\n",
       " 'help',\n",
       " 'towards',\n",
       " 'familiarization',\n",
       " 'data',\n",
       " 'collection',\n",
       " 'They',\n",
       " 'instrumental',\n",
       " 'helping',\n",
       " 'contact',\n",
       " 'various',\n",
       " 'MCGM',\n",
       " 'departments',\n",
       " 'well',\n",
       " 'helping',\n",
       " 'establish',\n",
       " 'contact',\n",
       " 'personnel',\n",
       " 'government',\n",
       " 'departments',\n",
       " 'organizations',\n",
       " 'Many',\n",
       " 'thanks',\n",
       " 'MCGM',\n",
       " 'team',\n",
       " 'deploying',\n",
       " 'personnel',\n",
       " 'particularly',\n",
       " 'Mr.',\n",
       " 'Prasad',\n",
       " 'Gharat',\n",
       " 'extensive',\n",
       " 'field',\n",
       " 'visits',\n",
       " 'helped',\n",
       " 'understanding',\n",
       " 'actual',\n",
       " 'ground',\n",
       " 'conditions',\n",
       " 'We',\n",
       " 'apologize',\n",
       " 'inadvertently',\n",
       " 'omitted',\n",
       " 'anyone',\n",
       " 'acknowledgement',\n",
       " 'due',\n",
       " 'We',\n",
       " 'hope',\n",
       " 'anticipate',\n",
       " \"work's\",\n",
       " 'usefulness',\n",
       " 'intended',\n",
       " 'purpose']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cd31dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.Subodh Kumar', 'Mr.Rajeev Kuknoor', 'Mr.Sudhir Ghate', 'Mr.A.G. Marathe', 'Mr.R. Balachandran', 'Mr.V.K Phatak', 'Mr.A.N Kale', 'Mr.A .', 'Mr.Jagdish Talreja', 'Mr.Dinesh Naik', 'Mr.Hiren Daftardar', 'Ms.Anita Naik', 'Mr.Prasad Gharat']\n"
     ]
    }
   ],
   "source": [
    "name_list = list()\n",
    "check =  ['Mr.', 'Mrs.', 'Ms.']\n",
    "for idx, token in enumerate(tokens):\n",
    "    if token.startswith(tuple(check)) and idx < (len(tokens)-1):\n",
    "        name = token + tokens[idx+1] + ' ' +  tokens[idx+2]\n",
    "        name_list.append(name)\n",
    "\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae6014e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c420329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "Requirement already satisfied: lxml>=2.3.2 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from python-docx) (4.6.3)\n",
      "Building wheels for collected packages: python-docx\n",
      "  Building wheel for python-docx (setup.py): started\n",
      "  Building wheel for python-docx (setup.py): finished with status 'done'\n",
      "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=2750e6b90d2fb7331b46136f6fdf1febb112cb7154a1dfdca7f02f1b14ce0cfe\n",
      "  Stored in directory: c:\\users\\rvsha\\appdata\\local\\pip\\cache\\wheels\\83\\8b\\7c\\09ae60c42c7ba4ed2dddaf2b8b9186cb105255856d6ed3dba5\n",
      "Successfully built python-docx\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-0.8.11\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16e6fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b395361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a word file object\n",
    "doc = open(\"downloads/nidhi.docx\",\"rb\")\n",
    "#creating word reader object\n",
    "document = docx.Document(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12263283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ​NIDHI SHARMA C-15 Swapna Shilpa Apt. Ananta Nagar, Nr, M.J.International School Badlapur (E), Mumbai-421503 E-mail: nidhi2206sharma@gmail.com Mobile: 7977584842                                                                       ​       ​RESUME Professional Summary EDUCATION AND QUALIFICATION:       CERTIFICATION AND INTERNSHIP:  Trincetis TOSCA Automation Specialist Level 2  - 2018From: SEED InfoTech Ltd. (Thane, Mumbai)Trincetis TOSCA Automation Specialist Level 1  - 2018From: SEED InfoTech Ltd. (Thane, Mumbai)       Technical Skills:    Project Handled:Account Management System based on Visual Basic.K-yan Projector and Snapbizz POS – Assebling/Troubleshooting.Positive Aspects:    Ability to Deliver Optimum Performance under Pressure and Ready to Learn.   Self-Motivator and Hardworking.    Positive Attitude & Team Player.I hereby declare that all the information mentioned above is correct to best of my knowledge.    \t\t------- Nidhi Sharma\n"
     ]
    }
   ],
   "source": [
    "docu=\"\"\n",
    "for para in document.paragraphs:\n",
    "    docu += para.text\n",
    "#to see the output call docu\n",
    "print(docu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1aef9741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content of the paragraph 0 is ：   ​NIDHI SHARMA \n",
      "\n",
      "The content of the paragraph 1 is ：C-15 Swapna Shilpa Apt. \n",
      "\n",
      "The content of the paragraph 2 is ：Ananta Nagar, Nr, M.J.International School \n",
      "\n",
      "The content of the paragraph 3 is ：Badlapur (E), Mumbai-421503 \n",
      "\n",
      "The content of the paragraph 4 is ：E-mail: nidhi2206sharma@gmail.com \n",
      "\n",
      "The content of the paragraph 5 is ：Mobile: 7977584842\n",
      "\n",
      "The content of the paragraph 6 is ：                                                                       ​       ​RESUME \n",
      "\n",
      "The content of the paragraph 7 is ：Professional Summary \n",
      "\n",
      "The content of the paragraph 8 is ：\n",
      "\n",
      "The content of the paragraph 9 is ：\n",
      "\n",
      "The content of the paragraph 10 is ：\n",
      "\n",
      "The content of the paragraph 11 is ：\n",
      "\n",
      "The content of the paragraph 12 is ：\n",
      "\n",
      "The content of the paragraph 13 is ：\n",
      "\n",
      "The content of the paragraph 14 is ：\n",
      "\n",
      "The content of the paragraph 15 is ：EDUCATION AND QUALIFICATION: \n",
      "\n",
      "The content of the paragraph 16 is ： \n",
      "\n",
      "The content of the paragraph 17 is ： \n",
      "\n",
      "The content of the paragraph 18 is ： \n",
      "\n",
      "The content of the paragraph 19 is ： \n",
      "\n",
      "The content of the paragraph 20 is ： \n",
      "\n",
      "The content of the paragraph 21 is ： \n",
      "\n",
      "The content of the paragraph 22 is ：CERTIFICATION AND INTERNSHIP: \n",
      "\n",
      "The content of the paragraph 23 is ： \n",
      "\n",
      "The content of the paragraph 24 is ：Trincetis TOSCA Automation Specialist Level 2  - 2018\n",
      "\n",
      "The content of the paragraph 25 is ：From: SEED InfoTech Ltd. (Thane, Mumbai)\n",
      "\n",
      "The content of the paragraph 26 is ：Trincetis TOSCA Automation Specialist Level 1  - 2018\n",
      "\n",
      "The content of the paragraph 27 is ：From: SEED InfoTech Ltd. (Thane, Mumbai)\n",
      "\n",
      "The content of the paragraph 28 is ： \n",
      "\n",
      "The content of the paragraph 29 is ： \n",
      "\n",
      "The content of the paragraph 30 is ： \n",
      "\n",
      "The content of the paragraph 31 is ： \n",
      "\n",
      "The content of the paragraph 32 is ： \n",
      "\n",
      "The content of the paragraph 33 is ： \n",
      "\n",
      "The content of the paragraph 34 is ： Technical Skills: \n",
      "\n",
      "The content of the paragraph 35 is ：\n",
      "\n",
      "The content of the paragraph 36 is ：\n",
      "\n",
      "The content of the paragraph 37 is ： \n",
      "\n",
      "The content of the paragraph 38 is ： \n",
      "\n",
      "The content of the paragraph 39 is ： Project Handled:\n",
      "\n",
      "The content of the paragraph 40 is ：\n",
      "\n",
      "The content of the paragraph 41 is ：Account Management System based on Visual Basic.\n",
      "\n",
      "The content of the paragraph 42 is ：K-yan Projector and Snapbizz POS – Assebling/Troubleshooting.\n",
      "\n",
      "The content of the paragraph 43 is ：\n",
      "\n",
      "The content of the paragraph 44 is ：\n",
      "\n",
      "The content of the paragraph 45 is ：\n",
      "\n",
      "The content of the paragraph 46 is ：\n",
      "\n",
      "The content of the paragraph 47 is ：Positive Aspects: \n",
      "\n",
      "The content of the paragraph 48 is ：\n",
      "\n",
      "The content of the paragraph 49 is ：   Ability to Deliver Optimum Performance under Pressure and Ready to Learn.\n",
      "\n",
      "The content of the paragraph 50 is ：   Self-Motivator and Hardworking.\n",
      "\n",
      "The content of the paragraph 51 is ：    Positive Attitude & Team Player.\n",
      "\n",
      "The content of the paragraph 52 is ：\n",
      "\n",
      "The content of the paragraph 53 is ：\n",
      "\n",
      "The content of the paragraph 54 is ：\n",
      "\n",
      "The content of the paragraph 55 is ：\n",
      "\n",
      "The content of the paragraph 56 is ：\n",
      "\n",
      "The content of the paragraph 57 is ：I hereby declare that all the information mentioned above is correct to best of my knowledge.\n",
      "\n",
      "The content of the paragraph 58 is ：\n",
      "\n",
      "The content of the paragraph 59 is ：    \t\t------- Nidhi Sharma\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  output paragraph number and paragraph content \n",
    "for i in range(len(document.paragraphs)):\n",
    "    print(\"The content of the paragraph \"+ str(i)+\" is ：\" + document.paragraphs[i].text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d10f5552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from bs4) (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=f1f7bbd90b146d1450a2aa9497f230213ce417d86445b8557259f5aeaee39d0e\n",
      "  Stored in directory: c:\\users\\rvsha\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9310bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib2\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93e32d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urllib2.urlopen('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
    "html_doc = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c80e3c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Natural language processing - Wikipedia\n",
      "  </title>\n",
      "  <script>\n",
      "   document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"51d0f488-8298-493f-99e8-d29e0709e631\",\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Natural_language_processing\",\"wgTitle\":\"Natural language processing\",\"wgCurRevisionId\":1112038569,\"wgRevisionId\":1112038569,\"wgArticleId\":21652,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"All accuracy disputes\",\"Accuracy disputes from December 2013\",\"CS1 maint: location\",\"Articles w\n"
     ]
    }
   ],
   "source": [
    "#Parsing\n",
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "# Formating the parsed html file\n",
    "strhtm = soup.prettify()\n",
    "# Print few lines\n",
    "print (strhtm[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a30af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Natural language processing - Wikipedia</title>\n",
      "Natural language processing - Wikipedia\n",
      "None\n",
      "Natural language processing\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.title.string)\n",
    "print(soup.a.string)\n",
    "print(soup.b.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "970c2499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Jump to navigation\n",
      "Jump to search\n",
      "Language processing in the brain\n",
      "None\n",
      "None\n",
      "automated online assistant\n",
      "customer service\n",
      "[1]\n",
      "linguistics\n",
      "computer science\n",
      "artificial intelligence\n",
      "natural language\n",
      "contextual\n",
      "speech recognition\n",
      "natural-language understanding\n",
      "natural-language generation\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "edit\n",
      "History of natural language processing\n",
      "Alan Turing\n",
      "Computing Machinery and Intelligence\n",
      "Turing test\n",
      "edit\n",
      "John Searle\n",
      "Chinese room\n",
      "Georgetown experiment\n",
      "automatic translation\n",
      "[2]\n",
      "ALPAC report\n",
      "statistical machine translation\n",
      "SHRDLU\n",
      "blocks worlds\n",
      "ELIZA\n",
      "Rogerian psychotherapist\n",
      "Joseph Weizenbaum\n",
      "ontologies\n",
      "chatterbots\n",
      "PARRY\n",
      "HPSG\n",
      "generative grammar\n",
      "[3]\n",
      "Lesk algorithm\n",
      "[4]\n",
      "Rhetorical Structure Theory\n",
      "Racter\n",
      "Jabberwacky\n",
      "[5]\n",
      "edit\n",
      "machine learning\n",
      "Moore's law\n",
      "Chomskyan\n",
      "transformational grammar\n",
      "corpus linguistics\n",
      "[6]\n",
      "machine translation\n",
      "textual corpora\n",
      "Parliament of Canada\n",
      "European Union\n",
      "unsupervised\n",
      "semi-supervised learning\n",
      "supervised learning\n",
      "World Wide Web\n",
      "time complexity\n",
      "edit\n",
      "representation learning\n",
      "deep neural network\n",
      "[7]\n",
      "[8]\n",
      "language modeling\n",
      "[9]\n",
      "[10]\n",
      "[11]\n",
      "in medicine and healthcare\n",
      "electronic health records\n",
      "[12]\n",
      "edit\n",
      "[13]\n",
      "[14]\n",
      "stemming\n",
      "machine-learning\n",
      "Apertium\n",
      "tokenization\n",
      "knowledge extraction\n",
      "edit\n",
      "[15]\n",
      "[16]\n",
      "statistical inference\n",
      "corpora\n",
      "statistical models\n",
      "probabilistic\n",
      "real-valued\n",
      "embeddings\n",
      "[17]\n",
      "[18]\n",
      "decision trees\n",
      "part-of-speech tagging\n",
      "hidden Markov models\n",
      "real-valued\n",
      "cache language models\n",
      "speech recognition\n",
      "edit\n",
      "Artificial neural network\n",
      "[19]\n",
      "neural networks\n",
      "word embeddings\n",
      "neural machine translation\n",
      "sequence-to-sequence\n",
      "statistical machine translation\n",
      "edit\n",
      "edit\n",
      "Optical character recognition\n",
      "Speech recognition\n",
      "text to speech\n",
      "AI-complete\n",
      "natural speech\n",
      "speech segmentation\n",
      "coarticulation\n",
      "analog signal\n",
      "Speech segmentation\n",
      "speech recognition\n",
      "Text-to-speech\n",
      "[20]\n",
      "Word segmentation\n",
      "Tokenization\n",
      "English\n",
      "Chinese\n",
      "Japanese\n",
      "Thai\n",
      "vocabulary\n",
      "morphology\n",
      "bag of words\n",
      "edit\n",
      "Lemmatization\n",
      "[21]\n",
      "Morphological segmentation\n",
      "morphemes\n",
      "morphology\n",
      "English\n",
      "inflectional morphology\n",
      "Turkish\n",
      "Meitei\n",
      "[22]\n",
      "agglutinated\n",
      "Part-of-speech tagging\n",
      "part of speech\n",
      "noun\n",
      "verb\n",
      "adjective\n",
      "Stemming\n",
      "edit\n",
      "Grammar induction\n",
      "[23]\n",
      "formal grammar\n",
      "Sentence breaking\n",
      "sentence boundary disambiguation\n",
      "periods\n",
      "punctuation marks\n",
      "abbreviations\n",
      "Parsing\n",
      "parse tree\n",
      "grammar\n",
      "natural languages\n",
      "ambiguous\n",
      "probabilistic context-free grammar\n",
      "stochastic grammar\n",
      "edit\n",
      "Lexical semantics\n",
      "Distributional semantics\n",
      "Named entity recognition\n",
      "capitalization\n",
      "named entity\n",
      "Chinese\n",
      "Arabic\n",
      "German\n",
      "nouns\n",
      "French\n",
      "Spanish\n",
      "adjectives\n",
      "Sentiment analysis\n",
      "Multimodal sentiment analysis\n",
      "Terminology extraction\n",
      "Word-sense disambiguation\n",
      "meaning\n",
      "WordNet\n",
      "Entity linking\n",
      "named entities\n",
      "edit\n",
      "Relationship extraction\n",
      "Semantic parsing\n",
      "AMR parsing\n",
      "DRT parsing\n",
      "Natural language understanding\n",
      "Semantic role labelling\n",
      "frames\n",
      "semantic roles\n",
      "edit\n",
      "Coreference resolution\n",
      "Anaphora resolution\n",
      "pronouns\n",
      "referring expressions\n",
      "Discourse analysis\n",
      "discourse\n",
      "speech acts\n",
      "frames\n",
      "Semantic role labelling\n",
      "pro-drop languages\n",
      "Recognizing textual entailment\n",
      "[24]\n",
      "Topic segmentation\n",
      "Argument mining\n",
      "natural language\n",
      "[25]\n",
      "argument scheme\n",
      "[26]\n",
      "[27]\n",
      "edit\n",
      "Automatic summarization\n",
      "[28]\n",
      "1 the Road\n",
      "language models\n",
      "[29]\n",
      "Dialogue management\n",
      "Document AI\n",
      "[30]\n",
      "[31]\n",
      "[32]\n",
      "[33]\n",
      "GPT-2\n",
      "Machine translation\n",
      "AI-complete\n",
      "Natural-language generation\n",
      "Natural-language understanding\n",
      "first-order logic\n",
      "computer\n",
      "closed-world assumption\n",
      "open-world assumption\n",
      "[34]\n",
      "Question answering\n",
      "Text-to-image generation\n",
      "[35]\n",
      "3D model\n",
      "[36]\n",
      "[37]\n",
      "edit\n",
      "[38]\n",
      "edit\n",
      "Cognition\n",
      "[39]\n",
      "Cognitive science\n",
      "[40]\n",
      "Cognitive linguistics\n",
      "[41]\n",
      "symbolic NLP\n",
      "George Lakoff\n",
      "cognitive linguistics\n",
      "[42]\n",
      "conceptual metaphor\n",
      "[43]\n",
      "probabilistic context-free grammar\n",
      "US patent 9269353\n",
      "[44]\n",
      "[45]\n",
      "[46]\n",
      "ACT-R\n",
      "[47]\n",
      "ACL\n",
      "explainability\n",
      "[48]\n",
      "multimodal\n",
      "[49]\n",
      "edit\n",
      "1 the Road\n",
      "Automated essay scoring\n",
      "Biomedical text mining\n",
      "Compound term processing\n",
      "Computational linguistics\n",
      "Computer-assisted reviewing\n",
      "Controlled natural language\n",
      "Deep learning\n",
      "Deep linguistic processing\n",
      "Distributional semantics\n",
      "Foreign language reading aid\n",
      "Foreign language writing aid\n",
      "Information extraction\n",
      "Information retrieval\n",
      "Language and Communication Technologies\n",
      "Language technology\n",
      "Latent semantic indexing\n",
      "Native-language identification\n",
      "Natural-language programming\n",
      "Natural-language understanding\n",
      "Natural-language search\n",
      "Outline of natural language processing\n",
      "Query expansion\n",
      "Query understanding\n",
      "Reification (linguistics)\n",
      "Speech processing\n",
      "Spoken dialogue systems\n",
      "Text-proofing\n",
      "Text simplification\n",
      "Transformer (machine learning model)\n",
      "Truecasing\n",
      "Question answering\n",
      "Word2vec\n",
      "edit\n",
      "^\n",
      "doi\n",
      "10.1145/1643823.1643908\n",
      "ISBN\n",
      "9781605588292\n",
      "^\n",
      "\"The history of machine translation in a nutshell\"\n",
      "self-published source\n",
      "^\n",
      "Koskenniemi, Kimmo\n",
      "Two-level morphology: A general computational model of word-form recognition and production\n",
      "University of Helsinki\n",
      "^\n",
      "Control of Inference: Role of Some Aspects of Discourse Structure-Centering\n",
      "^\n",
      "doi\n",
      "10.1109/PROC.1986.13580\n",
      "ISSN\n",
      "1558-2256\n",
      "S2CID\n",
      "30688575\n",
      "^\n",
      "corner cases\n",
      "pathological\n",
      "thought experiments\n",
      "corpus linguistics\n",
      "corpora\n",
      "poverty of the stimulus\n",
      "^\n",
      "arXiv\n",
      "1807.10854\n",
      "doi\n",
      "10.1613/jair.4992\n",
      "S2CID\n",
      "8273530\n",
      "^\n",
      "Deep Learning\n",
      "^\n",
      "arXiv\n",
      "1602.02410\n",
      "Bibcode\n",
      "2016arXiv160202410J\n",
      "^\n",
      "\"Parsing as Language Modeling\"\n",
      "the original\n",
      "^\n",
      "\"Grammar as a Foreign Language\"\n",
      "arXiv\n",
      "1412.7449\n",
      "Bibcode\n",
      "2014arXiv1412.7449V\n",
      "^\n",
      "\"Using Natural Language Processing to Measure and Improve Quality of Diabetes Care: A Systematic Review\"\n",
      "doi\n",
      "10.1177/19322968211000831\n",
      "ISSN\n",
      "1932-2968\n",
      "PMC\n",
      "8120048\n",
      "PMID\n",
      "33736486\n",
      "^\n",
      "Procedures as a Representation for Data in a Computer Program for Understanding Natural Language\n",
      "^\n",
      "ISBN\n",
      "0-470-99033-3\n",
      "^\n",
      "Mark Johnson. How the statistical revolution changes (computational) linguistics.\n",
      "^\n",
      "Philip Resnik. Four revolutions.\n",
      "^\n",
      "\"Investigating complex-valued representation in NLP\"\n",
      "^\n",
      "arXiv\n",
      "1705.09792\n",
      "cs.NE\n",
      "^\n",
      "\"Deep Learning For NLP-ACL 2012 Tutorial\"\n",
      "^\n",
      "CiteSeerX\n",
      "10.1.1.668.869\n",
      "doi\n",
      "10.1007/978-3-642-29364-1_2\n",
      "ISBN\n",
      "9783642293634\n",
      "^\n",
      "\"What is Natural Language Processing? Intro to NLP in Machine Learning\"\n",
      "^\n",
      "\"Manipuri Morpheme Identification\"\n",
      "cite journal\n",
      "link\n",
      "^\n",
      "\"Natural language grammar induction using a constituent-context model\"\n",
      "^\n",
      "https://tac.nist.gov//2011/RTE/\n",
      "^\n",
      "\"Argumentation Mining: State of the Art and Emerging Trends\"\n",
      "doi\n",
      "10.1145/2850417\n",
      "hdl\n",
      "11585/523460\n",
      "ISSN\n",
      "1533-5399\n",
      "S2CID\n",
      "9561587\n",
      "^\n",
      "\"Argument Mining - IJCAI2016 Tutorial\"\n",
      "^\n",
      "\"NLP Approaches to Computational Argumentation – ACL 2016, Berlin\"\n",
      "^\n",
      "\"U B U W E B :: Racter\"\n",
      "^\n",
      "doi\n",
      "10.1007/978-3-030-16800-1\n",
      "ISBN\n",
      "978-3-030-16799-8\n",
      "S2CID\n",
      "155818532\n",
      "^\n",
      "\"Document Understanding AI on Google Cloud (Cloud Next '19) - YouTube\"\n",
      "the original\n",
      "^\n",
      "\"Centre for Language Technology (CLT)\"\n",
      "^\n",
      "\"Shared Task: Grammatical Error Correction\"\n",
      "^\n",
      "\"Shared Task: Grammatical Error Correction\"\n",
      "^\n",
      "\"Formalizing Semantic of Natural Language through Conceptualization from Existence\"\n",
      "the original\n",
      "^\n",
      "\"OpenAI's DALL-E AI image generator can now edit pictures, too\"\n",
      "^\n",
      "\"The Stanford Natural Language Processing Group\"\n",
      "^\n",
      "\"WordsEye: an automatic text-to-scene conversion system\"\n",
      "doi\n",
      "10.1145/383259.383316\n",
      "ISBN\n",
      "978-1-58113-374-5\n",
      "S2CID\n",
      "3842372\n",
      "^\n",
      "\"Previous shared tasks | CoNLL\"\n",
      "^\n",
      "\"Cognition\"\n",
      "Oxford University Press\n",
      "Dictionary.com\n",
      "the original\n",
      "^\n",
      "\"Ask the Cognitive Scientist\"\n",
      "^\n",
      "ISBN\n",
      "978-0-805-85352-0\n",
      "^\n",
      "ISBN\n",
      "978-0-465-05674-3\n",
      "^\n",
      "ISBN\n",
      "978-0-521-59541-4\n",
      "^\n",
      "\"Universal Conceptual Cognitive Annotation (UCCA)\"\n",
      "^\n",
      "Building an RRG computational grammar\n",
      "^\n",
      "\"Fluid Construction Grammar – A fully operational processing system for construction grammars\"\n",
      "^\n",
      "\"ACL Member Portal | The Association for Computational Linguistics Member Portal\"\n",
      "^\n",
      "\"Chunks and Rules\"\n",
      "^\n",
      "\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\"\n",
      "doi\n",
      "10.1162/tacl_a_00177\n",
      "S2CID\n",
      "2317858\n",
      "edit\n",
      "\"Models of natural language understanding\"\n",
      "Bibcode\n",
      "1995PNAS...92.9977B\n",
      "doi\n",
      "10.1073/pnas.92.22.9977\n",
      "PMC\n",
      "40721\n",
      "PMID\n",
      "7479812\n",
      "ISBN\n",
      "978-0-596-51649-9\n",
      "ISBN\n",
      "978-0-13-187321-6\n",
      "ISBN\n",
      "978-1848218482\n",
      "ISBN\n",
      "978-1848219212\n",
      "ISBN\n",
      "978-0-521-86571-5\n",
      "Official html and pdf versions available without charge.\n",
      "ISBN\n",
      "978-0-262-13360-9\n",
      "ISBN\n",
      "978-0-387-19557-5\n",
      "edit\n",
      "None\n",
      "Natural language processing\n",
      "v\n",
      "t\n",
      "e\n",
      "Natural language processing\n",
      "AI-complete\n",
      "Bag-of-words\n",
      "n-gram\n",
      "Bigram\n",
      "Trigram\n",
      "Computational linguistics\n",
      "Natural-language understanding\n",
      "Stop words\n",
      "Text processing\n",
      "Text analysis\n",
      "Collocation extraction\n",
      "Concept mining\n",
      "Coreference resolution\n",
      "Deep linguistic processing\n",
      "Distant reading\n",
      "Information extraction\n",
      "Named-entity recognition\n",
      "Ontology learning\n",
      "Parsing\n",
      "Part-of-speech tagging\n",
      "Semantic role labeling\n",
      "Semantic similarity\n",
      "Sentiment analysis\n",
      "Terminology extraction\n",
      "Text mining\n",
      "Textual entailment\n",
      "Truecasing\n",
      "Word-sense disambiguation\n",
      "Word-sense induction\n",
      "Text segmentation\n",
      "Compound-term processing\n",
      "Lemmatisation\n",
      "Lexical analysis\n",
      "Text chunking\n",
      "Stemming\n",
      "Sentence segmentation\n",
      "Word segmentation\n",
      "Automatic summarization\n",
      "Multi-document summarization\n",
      "Sentence extraction\n",
      "Text simplification\n",
      "Machine translation\n",
      "Computer-assisted\n",
      "Example-based\n",
      "Rule-based\n",
      "Statistical\n",
      "Transfer-based\n",
      "Neural\n",
      "Distributional semantics\n",
      "BERT\n",
      "Document-term matrix\n",
      "Explicit semantic analysis\n",
      "fastText\n",
      "GloVe\n",
      "Latent semantic analysis\n",
      "Word embedding\n",
      "Word2vec\n",
      "Language resources\n",
      "Corpus linguistics\n",
      "Lexical resource\n",
      "Linguistic Linked Open Data\n",
      "Machine-readable dictionary\n",
      "Parallel text\n",
      "PropBank\n",
      "Semantic network\n",
      "Simple Knowledge Organization System\n",
      "Speech corpus\n",
      "Text corpus\n",
      "Thesaurus (information retrieval)\n",
      "Treebank\n",
      "Universal Dependencies\n",
      "BabelNet\n",
      "Bank of English\n",
      "DBpedia\n",
      "FrameNet\n",
      "Google Ngram Viewer\n",
      "UBY\n",
      "WordNet\n",
      "None\n",
      "Speech recognition\n",
      "Speech segmentation\n",
      "Speech synthesis\n",
      "Natural language generation\n",
      "Optical character recognition\n",
      "Topic model\n",
      "Document classification\n",
      "Latent Dirichlet allocation\n",
      "Pachinko allocation\n",
      "None\n",
      "Automated essay scoring\n",
      "Concordancer\n",
      "Grammar checker\n",
      "Predictive text\n",
      "Spell checker\n",
      "Syntax guessing\n",
      "None\n",
      "Chatbot\n",
      "Interactive fiction\n",
      "Question answering\n",
      "Virtual assistant\n",
      "Voice user interface\n",
      "Natural Language Toolkit\n",
      "spaCy\n",
      "Portal\n",
      "None\n",
      "Language\n",
      "Authority control: National libraries\n",
      "None\n",
      "Israel\n",
      "United States\n",
      "Japan\n",
      "Czech Republic\n",
      "https://en.wikipedia.org/w/index.php?title=Natural_language_processing&oldid=1112038569\n",
      "Categories\n",
      "Natural language processing\n",
      "Artificial intelligence\n",
      "Computational fields of study\n",
      "Computational linguistics\n",
      "Speech recognition\n",
      "All accuracy disputes\n",
      "Accuracy disputes from December 2013\n",
      "CS1 maint: location\n",
      "Articles with short description\n",
      "Short description is different from Wikidata\n",
      "Commons category link from Wikidata\n",
      "Articles with J9U identifiers\n",
      "Articles with LCCN identifiers\n",
      "Articles with NDL identifiers\n",
      "Articles with NKC identifiers\n",
      "Talk\n",
      "Contributions\n",
      "Create account\n",
      "Log in\n",
      "Article\n",
      "Talk\n",
      "Read\n",
      "Edit\n",
      "View history\n",
      "None\n",
      "Main page\n",
      "Contents\n",
      "Current events\n",
      "Random article\n",
      "About Wikipedia\n",
      "Contact us\n",
      "Donate\n",
      "Help\n",
      "Learn to edit\n",
      "Community portal\n",
      "Recent changes\n",
      "Upload file\n",
      "What links here\n",
      "Related changes\n",
      "Upload file\n",
      "Special pages\n",
      "Permanent link\n",
      "Page information\n",
      "Cite this page\n",
      "Wikidata item\n",
      "Download as PDF\n",
      "Printable version\n",
      "Wikimedia Commons\n",
      "Wikiversity\n",
      "Afrikaans\n",
      "العربية\n",
      "Azərbaycanca\n",
      "বাংলা\n",
      "Bân-lâm-gú\n",
      "Беларуская\n",
      "Беларуская (тарашкевіца)\n",
      "Български\n",
      "Bosanski\n",
      "Català\n",
      "Čeština\n",
      "Dansk\n",
      "Deutsch\n",
      "Eesti\n",
      "Ελληνικά\n",
      "Español\n",
      "Euskara\n",
      "فارسی\n",
      "Français\n",
      "Galego\n",
      "한국어\n",
      "Հայերեն\n",
      "हिन्दी\n",
      "Hrvatski\n",
      "Bahasa Indonesia\n",
      "Íslenska\n",
      "Italiano\n",
      "עברית\n",
      "ಕನ್ನಡ\n",
      "ქართული\n",
      "Lietuvių\n",
      "Македонски\n",
      "मराठी\n",
      "مصرى\n",
      "Монгол\n",
      "မြန်မာဘာသာ\n",
      "日本語\n",
      "ଓଡ଼ିଆ\n",
      "Picard\n",
      "Piemontèis\n",
      "Polski\n",
      "Português\n",
      "Română\n",
      "Русский\n",
      "Simple English\n",
      "کوردی\n",
      "Српски / srpski\n",
      "Srpskohrvatski / српскохрватски\n",
      "Suomi\n",
      "தமிழ்\n",
      "ไทย\n",
      "Türkçe\n",
      "Українська\n",
      "Tiếng Việt\n",
      "粵語\n",
      "中文\n",
      "Edit links\n",
      "Creative Commons Attribution-ShareAlike License 3.0\n",
      "None\n",
      "Terms of Use\n",
      "Privacy Policy\n",
      "Wikimedia Foundation, Inc.\n",
      "Privacy policy\n",
      "About Wikipedia\n",
      "Disclaimers\n",
      "Contact Wikipedia\n",
      "Mobile view\n",
      "Developers\n",
      "Statistics\n",
      "Cookie statement\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for x in soup.find_all('a'): \n",
    "    print(x.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f340944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.  The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\n",
      "\n",
      "Challenges in natural language processing frequently involve speech recognition, natural-language understanding, and natural-language generation.\n",
      "\n",
      "Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence. The proposed test includes a task that involves the automated interpretation and generation of natural language.\n",
      "\n",
      "The premise of symbolic NLP is well-summarized by John Searle's Chinese room experiment: Given a collection of rules (e.g., a Chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other NLP tasks) by applying those rules to the data it confronts.\n",
      "\n",
      "Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.  Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.  This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[6]\n",
      "\n",
      "In the 2010s, representation learning and deep neural network-style machine learning methods became widespread in natural language processing. That popularity was due partly to a flurry of results showing that such techniques[7][8] can achieve state-of-the-art results in many natural language tasks, e.g., in language modeling[9] and parsing.[10][11] This is increasingly important in medicine and healthcare, where NLP helps analyze notes and text in electronic health records that would otherwise be inaccessible for study when seeking to improve care.[12]\n",
      "\n",
      "In the early days, many language-processing systems were designed by symbolic methods, i.e., the hand-coding of a set of rules, coupled with a dictionary lookup:[13][14] such as by writing grammars or devising heuristic rules for stemming.\n",
      "\n",
      "More recent systems based on machine-learning algorithms have many advantages over hand-produced rules: \n",
      "\n",
      "Despite the popularity of machine learning in NLP research, symbolic methods are still (2020) commonly used:\n",
      "\n",
      "Since the so-called \"statistical revolution\"[15][16] in the late 1980s and mid-1990s, much natural language processing research has relied heavily on machine learning. The machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora (the plural form of corpus, is a set of documents, possibly with human or computer annotations) of typical real-world examples.\n",
      "\n",
      "Many different classes of machine-learning algorithms have been applied to natural-language-processing tasks. These algorithms take as input a large set of \"features\" that are generated from the input data. Increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature (complex-valued embeddings,[17] and neural networks in general have also been proposed, for e.g. speech[18]). Such models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system.\n",
      "\n",
      "Some of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules.  However, part-of-speech tagging introduced the use of hidden Markov models to natural language processing, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. The cache language models upon which many speech recognition systems now rely are examples of such statistical models.  Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks.\n",
      "\n",
      "Since the neural turn, statistical methods in NLP research have been largely replaced by neural networks. However, they continue to be relevant for contexts in which statistical interpretability and transparency is required.\n",
      "\n",
      "A major drawback of statistical methods is that they require elaborate feature engineering. Since 2015,[19] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning. Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing). In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing. For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation (SMT).\n",
      "\n",
      "The following is a list of some of the most commonly researched tasks in natural language processing. Some of these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks.\n",
      "\n",
      "Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below.\n",
      "\n",
      "Based on long-standing trends in the field, it is possible to extrapolate future directions of NLP. As of 2020, three trends among the topics of the long-standing series of CoNLL Shared Tasks can be observed:[38]\n",
      "\n",
      "Most higher-level NLP applications involve aspects that emulate intelligent behaviour and apparent comprehension of natural language. More broadly speaking, the technical operationalization of increasingly advanced aspects of cognitive behaviour represents one of the developmental trajectories of NLP (see trends among CoNLL shared tasks above).\n",
      "\n",
      "Cognition refers to \"the mental action or process of acquiring knowledge and understanding through thought, experience, and the senses.\"[39] Cognitive science is the interdisciplinary, scientific study of the mind and its processes.[40] Cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.[41] Especially during the age of symbolic NLP, the area of computational linguistics maintained strong ties with cognitive studies.\n",
      "\n",
      "As an example, George Lakoff offers a methodology to build natural language processing (NLP) algorithms through the perspective of cognitive science, along with the findings of cognitive linguistics,[42] with two defining aspects:\n",
      "\n",
      "Ties with cognitive linguistics are part of the historical heritage of NLP, but they have been less frequently addressed since the statistical turn during the 1990s. Nevertheless, approaches to develop cognitive models towards technically operationalizable frameworks have been pursued in the context of various frameworks, e.g., of cognitive grammar,[44] functional grammar,[45] construction grammar,[46] computational psycholinguistics and cognitive neuroscience (e.g., ACT-R), however, with limited uptake in mainstream NLP (as measured by presence on major conferences[47] of the ACL). More recently, ideas of cognitive NLP have been revived as an approach to achieve explainability, e.g., under the notion of \"cognitive AI\".[48] Likewise, ideas of cognitive NLP are inherent to neural models multimodal NLP (although rarely made explicit).[49]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in soup.find_all('p'): \n",
    "    print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d4bcc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries.\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3559428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"success\": {\n",
      "      \"total\": 1\n",
      "   },\n",
      "   \"contents\": {\n",
      "      \"quotes\": [\n",
      "         {\n",
      "            \"quote\": \"Great things are done by a series of small things brought together.\",\n",
      "            \"length\": \"67\",\n",
      "            \"author\": \"Vincent Van Gogh\",\n",
      "            \"tags\": [\n",
      "               \"art\",\n",
      "               \"inspire\",\n",
      "               \"small-things\"\n",
      "            ],\n",
      "            \"category\": \"inspire\",\n",
      "            \"language\": \"en\",\n",
      "            \"date\": \"2022-10-09\",\n",
      "            \"permalink\": \"https://theysaidso.com/quote/vincent-van-gogh-great-things-are-done-by-a-series-of-small-things-brought-toget\",\n",
      "            \"id\": \"DLThmumKP4CCe1833rRvNQeF\",\n",
      "            \"background\": \"https://theysaidso.com/img/qod/qod-inspire.jpg\",\n",
      "            \"title\": \"Inspiring Quote of the day\"\n",
      "         }\n",
      "      ]\n",
      "   },\n",
      "   \"baseurl\": \"https://theysaidso.com\",\n",
      "   \"copyright\": {\n",
      "      \"year\": 2024,\n",
      "      \"url\": \"https://theysaidso.com\"\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#extracting the text from \"https://quotes.rest/qod.json\"\n",
    "r = requests.get(\"https://quotes.rest/qod.json\")\n",
    "res = r.json()\n",
    "print(json.dumps(res, indent = 3)) # 4 spaces gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "088826b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': 'Great things are done by a series of small things brought together.',\n",
       " 'length': '67',\n",
       " 'author': 'Vincent Van Gogh',\n",
       " 'tags': ['art', 'inspire', 'small-things'],\n",
       " 'category': 'inspire',\n",
       " 'language': 'en',\n",
       " 'date': '2022-10-09',\n",
       " 'permalink': 'https://theysaidso.com/quote/vincent-van-gogh-great-things-are-done-by-a-series-of-small-things-brought-toget',\n",
       " 'id': 'DLThmumKP4CCe1833rRvNQeF',\n",
       " 'background': 'https://theysaidso.com/img/qod/qod-inspire.jpg',\n",
       " 'title': 'Inspiring Quote of the day'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract contents\n",
    "q = res['contents']['quotes'][0]\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e400eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great things are done by a series of small things brought together. \n",
      "-- Vincent Van Gogh\n"
     ]
    }
   ],
   "source": [
    "#extract only quote\n",
    "print(q['quote'], '\\n--', q['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57235d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 2024, 'url': 'https://theysaidso.com'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = res['copyright']\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61e5bd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emot\n",
      "  Downloading emot-3.1-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: emot\n",
      "Successfully installed emot-3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bfd1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sample text data with emoji\n",
    "text1 = \"What are you saying 😂. I am the boss 😎, and why are you so 😒\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ede5c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from emot.emo_unicode import UNICODE_EMOJI\n",
    "from emot.emo_unicode import EMOTICONS_EMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce34f960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are you saying face_with_tears_of_joy. I am the boss smiling_face_with_sunglasses, and why are you so unamused_face'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for converting emojis into word\n",
    "def converting_emojis(text):\n",
    "    for emot in UNICODE_EMOJI:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text\n",
    "\n",
    "converting_emojis(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e71d8067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are you saying . I am the boss , and why are you so '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emoji_removal(string):\n",
    "    emoji_unicodes = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols \n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport \n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  \n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  \n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_unicodes.sub(r'', string)\n",
    "emoji_removal(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3dd6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example sentences\n",
    "sentences = [['I', 'love', 'nlp'],\n",
    " ['I', 'will', 'learn', 'nlp', 'in', '2','months'],\n",
    " ['nlp', 'is', 'future'],\n",
    " ['nlp', 'saves', 'time', 'and', 'solves', 'lot', 'of', 'industry', 'problems'],\n",
    " ['nlp', 'uses', 'machine', 'learning']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c170e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp39-cp39-win_amd64.whl (23.9 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.2.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\rvsha\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0 smart-open-6.2.0\n"
     ]
    }
   ],
   "source": [
    "# install gensim\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1486405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "493286b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=21, vector_size=50, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "# sg - skipgram - 0:CBOW, 1 :Skipram\n",
    "# window : distance between a target word and word around\n",
    "skipgram = Word2Vec(sentences, vector_size =50, window = 3, min_count=1,sg = 1)\n",
    "print(skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b84124d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0724545e-03  4.7286032e-04  1.0206699e-02  1.8018546e-02\n",
      " -1.8605899e-02 -1.4233618e-02  1.2917743e-02  1.7945977e-02\n",
      " -1.0030856e-02 -7.5267460e-03  1.4761009e-02 -3.0669451e-03\n",
      " -9.0732286e-03  1.3108101e-02 -9.7203208e-03 -3.6320353e-03\n",
      "  5.7531595e-03  1.9837476e-03 -1.6570430e-02 -1.8897638e-02\n",
      "  1.4623532e-02  1.0140524e-02  1.3515387e-02  1.5257311e-03\n",
      "  1.2701779e-02 -6.8107317e-03 -1.8928051e-03  1.1537147e-02\n",
      " -1.5043277e-02 -7.8722099e-03 -1.5023164e-02 -1.8600845e-03\n",
      "  1.9076237e-02 -1.4638334e-02 -4.6675396e-03 -3.8754845e-03\n",
      "  1.6154870e-02 -1.1861792e-02  9.0322494e-05 -9.5074698e-03\n",
      " -1.9207101e-02  1.0014586e-02 -1.7519174e-02 -8.7836506e-03\n",
      " -7.0199967e-05 -5.9236528e-04 -1.5322480e-02  1.9229483e-02\n",
      "  9.9641131e-03  1.8466286e-02]\n"
     ]
    }
   ],
   "source": [
    "# access vector for one word\n",
    "print(skipgram.wv['nlp']) # word vector of nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5dc33672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.6279412e-02 -8.9312326e-03 -2.1488059e-03  2.0187509e-03\n",
      " -4.0156092e-04  2.2794984e-03  1.2237644e-02 -4.9323964e-05\n",
      " -6.5047117e-03 -3.0514349e-03  1.1802979e-02  3.0281371e-03\n",
      " -1.4249186e-03  1.8668110e-02 -9.8441625e-03 -1.6714988e-03\n",
      "  1.8358910e-02  1.3498767e-02  2.9817047e-03 -1.7790705e-02\n",
      "  2.2997502e-03 -4.5651412e-03  1.8746054e-02  2.4320469e-03\n",
      "  2.9764483e-03  4.8080273e-03 -3.6702408e-03 -9.9802641e-03\n",
      "  4.5069584e-04 -4.0067714e-03  1.3206967e-02  1.7881898e-02\n",
      " -1.3624289e-03  5.9530176e-03 -1.2224088e-02  3.3919991e-03\n",
      " -1.3837523e-02 -1.7406510e-02 -1.1832394e-02 -1.7918635e-02\n",
      "  1.4562343e-02 -1.1548452e-02  1.6556721e-02 -1.4493207e-02\n",
      "  6.8648313e-03  1.9353718e-02 -1.5564910e-02 -1.9917289e-02\n",
      " -8.6597214e-03 -5.3637647e-03]\n"
     ]
    }
   ],
   "source": [
    "# access vector for another one word\n",
    "print(skipgram.wv['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "476f2795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 0.1898709386587143),\n",
       " ('2', 0.044917330145835876),\n",
       " ('months', -0.010145983658730984),\n",
       " ('nlp', -0.014475286938250065),\n",
       " ('learning', -0.023208966478705406),\n",
       " ('saves', -0.032102733850479126),\n",
       " ('in', -0.04407234489917755),\n",
       " ('industry', -0.044128306210041046),\n",
       " ('problems', -0.08984725177288055),\n",
       " ('machine', -0.09488881379365921)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding Similar Words\n",
    "sim_words = skipgram.wv.most_similar('love')\n",
    "sim_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8794abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram.save('skipgram.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ab56053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('time', 0.1898709386587143),\n",
       " ('2', 0.044917330145835876),\n",
       " ('months', -0.010145983658730984),\n",
       " ('nlp', -0.014475286938250065),\n",
       " ('learning', -0.023208966478705406),\n",
       " ('saves', -0.032102733850479126),\n",
       " ('in', -0.04407234489917755),\n",
       " ('industry', -0.044128306210041046),\n",
       " ('problems', -0.08984725177288055),\n",
       " ('machine', -0.09488881379365921)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding Similar Words\n",
    "sim_words = skipgram.wv.most_similar('love')\n",
    "sim_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2440dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "skipgram = Word2Vec.load('skipgram.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d164f131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# T – SNE plot - Stochastin Neighbor Embedding\n",
    "X =  np.asarray(skipgram.wv.vectors)\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(skipgram.wv.key_to_index.keys())\n",
    "for i, word in enumerate(words):\n",
    "    pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8cb190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40797037\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "# load the saved model\n",
    "model = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format('./downloads/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#Checking how similarity works.\n",
    "print (model.similarity('this', 'is'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d45c26e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the odd one out.\n",
    "model.doesnt_match('breakfast cereal dinner lunch'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "beec3de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.518113374710083),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is also finding the relations between words.\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df20c601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
